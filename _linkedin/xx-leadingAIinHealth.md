---
layout: post
title: "What Does 'Leading AI in Health' Actually Mean?"
picture: /assets/images/projects/conference.webp
category: reflection
publish: True
date: 2025-02-12
---

You might've noticed my tagline: #LeadingAIinHealth

I've been asked: isn't that a bit presumptuous for a postdoc?

Fair question. Let me explain what I mean—and more importantly, what I don't mean.

What I don't mean:

❌ I'm not claiming to be the leader in AI for health. There are brilliant researchers decades ahead of me in experience, impact, and insight.

❌ I'm not saying my research is more important than others'. Healthcare AI is a massive field—clinical decision support, medical imaging, drug discovery, robotic surgery, epidemiology. I work on a small slice of it.

❌ I'm not positioning myself as a visionary guru. I'm a postdoc. I have two papers under review that might get rejected. I'm still figuring this out.

What I do mean:

When I say #LeadingAIinHealth, I mean three things:

1. Leading as in "directing towards impact"

I'm trying to steer AI methods toward actual healthcare problems—not just benchmarks that look good in papers.

Examples:

Federated learning isn't interesting to me because it's technically clever. It's interesting because hospitals can't share patient data, and this lets them collaborate anyway.
Tensor regression isn't just a cool math trick. It preserves the structure of longitudinal health data in ways that matter for clinical prediction.
Brain-computer interfaces aren't sci-fi novelties. They're tools that could restore communication for people with locked-in syndrome or control for people with paralysis.
If the AI doesn't eventually help patients, clinicians, or health systems—what's the point?

2. Leading as in "being at the front of emerging methods"

I'm working on techniques that are early-stage but have huge potential:

Federated learning for healthcare: Most FL research focuses on computer vision or NLP. Healthcare has unique challenges—small datasets, heterogeneous populations, regulatory complexity. I'm among the first wave of researchers translating FL to clinical settings.

Foundation models for precision medicine: Starting in December 2025, I'll be developing multi-modal AI integrating MRI, multi-omics, and clinical data for early cancer detection. This is cutting-edge—nobody has fully cracked multi-modal temporal modeling in oncology yet.

Privacy-preserving tensor methods: Combining tensor regression with federated learning (FBTTR) is genuinely novel. We've shown it works for BCI and cardiac prediction. Now scaling it to multi-institutional imaging and omics data.

Being at the front doesn't mean I'm the best. It means I'm working on problems that don't have established solutions yet. I'm figuring it out as I go, alongside other researchers doing the same.

3. Leading as in "taking responsibility"

AI in health isn't just a technical problem. It's an ethical, regulatory, and societal challenge.

When I deploy a federated learning model across hospitals, I'm responsible for:

Privacy: Does it actually protect patient data?
Fairness: Does it work equally well across different patient populations?
Interpretability: Can clinicians understand why the model made a prediction?
Safety: What happens if it gets something wrong?
"Leading" means I can't just publish and move on. I have to think about deployment, governance, and real-world consequences.

Examples of this in practice:

Co-authoring papers with 40+ authors across multiple countries (MS disability progression work) to ensure diverse clinical perspectives
Working with FAIR UC RWE to build governance frameworks, not just algorithms
Teaching students to think about when not to use AI, not just how to build it
Participating in EFSA (European Food Safety Authority) contracts on statistical analysis with regulatory implications
Why the tagline matters (to me):

When I started my postdoc at UHasselt, I was exhausted. Two years of pandemic PhD work, imposter syndrome, unclear career trajectory. I needed something to anchor my identity as a researcher.

#LeadingAIinHealth became that anchor. It reminds me:

What I'm aiming for: AI that matters in healthcare
Why I do this: To contribute to patient outcomes, not just publication counts
How I want to work: At the intersection of innovation and responsibility
It's aspirational, yes. But it's also actionable. Every project I take on, I ask: does this lead AI toward meaningful health impact?

The tension:

Here's the hard part: leading implies confidence, but research is full of uncertainty.

Is FBTTR really better than standard approaches, or have we just cherry-picked favorable examples?
Will foundation models for cancer detection work at scale, or will they fail in messy real-world data?
Am I actually helping healthcare, or just adding to the hype?
I don't have definitive answers. I'm making bets, testing hypotheses, learning from failures. The tagline is a north star, not a declaration of arrival.

What I'm learning:

1. "Leading" is collective, not individual I'm part of a wave of researchers (Ashkan Pirmani, Edward De Brouwer, Liesbet Peeters, Yves Moreau, dozens of others) pushing federated learning into healthcare. None of us are doing it alone.

2. Impact takes time My PhD work on tensor regression is only now (5 years later) being adopted by other groups. The FL work I'm doing today might not matter until 2030. Leading means playing the long game.

3. Visibility is part of the job If you develop a method and nobody knows about it, it doesn't help anyone. That's why I'm on LinkedIn, why I open-source code, why I teach. Leading means communicating, not just researching.

4. It's okay to be ambitious Early in my career, I downplayed my goals. "I just want to do good research." But if I'm honest? I want my work to change how healthcare uses AI. That's ambitious. I'm learning to own that.

So: #LeadingAIinHealth?

Yes. Not because I've arrived, but because that's the direction I'm moving.

Leading as in: trying to push methods toward real impact. Leading as in: working on emerging, high-potential techniques. Leading as in: taking responsibility for ethical, fair, and safe deployment.

And if it sounds a bit presumptuous for a postdoc? Maybe. But I'd rather aim too high and fall short than aim too low and wonder what might have been.

Working on: foundation models for cancer detection, federated learning for cardiovascular prediction, brain-computer interfaces for motor restoration. Trying to lead AI toward health impact, one paper at a time.

#LeadingAIinHealth #HealthcareAI #FederatedLearning #PrecisionMedicine #AcademicAmbition #ResearchImpact
